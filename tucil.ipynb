{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tugas Kecil 1 IF3270  \n",
    "## Eksplorasi library Algoritme Pembelajaran pada Jupyter Notebook\n",
    "\n",
    "\n",
    "Anggota Kelompok:\n",
    "- 13520065 - Rayhan Kinan Muhannad\n",
    "- 13520081 - Andhika Arta Aryanto\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
      "0        17.99         10.38          122.80     1001.0          0.11840   \n",
      "1        20.57         17.77          132.90     1326.0          0.08474   \n",
      "2        19.69         21.25          130.00     1203.0          0.10960   \n",
      "3        11.42         20.38           77.58      386.1          0.14250   \n",
      "4        20.29         14.34          135.10     1297.0          0.10030   \n",
      "\n",
      "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
      "0           0.27760          0.3001              0.14710         0.2419   \n",
      "1           0.07864          0.0869              0.07017         0.1812   \n",
      "2           0.15990          0.1974              0.12790         0.2069   \n",
      "3           0.28390          0.2414              0.10520         0.2597   \n",
      "4           0.13280          0.1980              0.10430         0.1809   \n",
      "\n",
      "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
      "0                 0.07871  ...          17.33           184.60      2019.0   \n",
      "1                 0.05667  ...          23.41           158.80      1956.0   \n",
      "2                 0.05999  ...          25.53           152.50      1709.0   \n",
      "3                 0.09744  ...          26.50            98.87       567.7   \n",
      "4                 0.05883  ...          16.67           152.20      1575.0   \n",
      "\n",
      "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
      "0            0.1622             0.6656           0.7119                0.2654   \n",
      "1            0.1238             0.1866           0.2416                0.1860   \n",
      "2            0.1444             0.4245           0.4504                0.2430   \n",
      "3            0.2098             0.8663           0.6869                0.2575   \n",
      "4            0.1374             0.2050           0.4000                0.1625   \n",
      "\n",
      "   worst symmetry  worst fractal dimension  target  \n",
      "0          0.4601                  0.11890       0  \n",
      "1          0.2750                  0.08902       0  \n",
      "2          0.3613                  0.08758       0  \n",
      "3          0.6638                  0.17300       0  \n",
      "4          0.2364                  0.07678       0  \n",
      "\n",
      "[5 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.utils import Bunch\n",
    "import pandas as pd\n",
    "\n",
    "data: Bunch = load_breast_cancer()\n",
    "\n",
    "# Konversi data ke dataframe\n",
    "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "df['target'] = pd.Series(data.target)\n",
    "\n",
    "# Print 5 data teratas\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 31 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   mean radius              569 non-null    float64\n",
      " 1   mean texture             569 non-null    float64\n",
      " 2   mean perimeter           569 non-null    float64\n",
      " 3   mean area                569 non-null    float64\n",
      " 4   mean smoothness          569 non-null    float64\n",
      " 5   mean compactness         569 non-null    float64\n",
      " 6   mean concavity           569 non-null    float64\n",
      " 7   mean concave points      569 non-null    float64\n",
      " 8   mean symmetry            569 non-null    float64\n",
      " 9   mean fractal dimension   569 non-null    float64\n",
      " 10  radius error             569 non-null    float64\n",
      " 11  texture error            569 non-null    float64\n",
      " 12  perimeter error          569 non-null    float64\n",
      " 13  area error               569 non-null    float64\n",
      " 14  smoothness error         569 non-null    float64\n",
      " 15  compactness error        569 non-null    float64\n",
      " 16  concavity error          569 non-null    float64\n",
      " 17  concave points error     569 non-null    float64\n",
      " 18  symmetry error           569 non-null    float64\n",
      " 19  fractal dimension error  569 non-null    float64\n",
      " 20  worst radius             569 non-null    float64\n",
      " 21  worst texture            569 non-null    float64\n",
      " 22  worst perimeter          569 non-null    float64\n",
      " 23  worst area               569 non-null    float64\n",
      " 24  worst smoothness         569 non-null    float64\n",
      " 25  worst compactness        569 non-null    float64\n",
      " 26  worst concavity          569 non-null    float64\n",
      " 27  worst concave points     569 non-null    float64\n",
      " 28  worst symmetry           569 non-null    float64\n",
      " 29  worst fractal dimension  569 non-null    float64\n",
      " 30  target                   569 non-null    int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 137.9 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Print informasi mengenai dataset\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['malignant' 'benign']\n"
     ]
    }
   ],
   "source": [
    "# Print informasi mengenai target\n",
    "print(data.target_names)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setelah melakukan eksplorasi singkat pada dataset, terdapat beberapa hal yang perlu diperhatikan:\n",
    "\n",
    "- Dataset yang digunakan memiliki 30 atribut, dimana 29 atribut merupakan atribut input dan 1 atribut merupakan atribut output (target). Seluruh atribut merupakan atribut numerik. \n",
    "\n",
    "Berarti, dalam konteks tugas kecil ini, 29 atribut input tersebut akan menjadi variabel prediktor dalam model machine learning untuk menentukan apakah suatu data termasuk data berkelas 0 (malignant) atau 1 (benign)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Membagi Dataset menjadi Data Training dan Data Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3147,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Membagi dataset menjadi 80% data training dan 20% data testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.2)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Melakukan pembelajaran dengan algoritma berikut ini:\n",
    "\n",
    "* Decision Tree Classifier (http://scikit-learn.org/stable/modules/tree.html)  \n",
    "* Id3 Estimator (https://github.com/svaante/decision-tree-id3)  \n",
    "* K-Means Clustering (https://scikit-learn.org/0.19/modules/generated/sklearn.cluster.KMeans.html  \n",
    "* Logistic Regression (https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)  \n",
    "* Neural Network (https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html)   \n",
    "* Support Vector Classifier (https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC)  \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Decision Tree Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|--- worst perimeter <= 114.45\n",
      "|   |--- worst concave points <= 0.16\n",
      "|   |   |--- worst concave points <= 0.14\n",
      "|   |   |   |--- worst radius <= 17.48\n",
      "|   |   |   |   |--- perimeter error <= 6.60\n",
      "|   |   |   |   |   |--- worst area <= 785.75\n",
      "|   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |--- worst area >  785.75\n",
      "|   |   |   |   |   |   |--- concavity error <= 0.05\n",
      "|   |   |   |   |   |   |   |--- worst area <= 790.80\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- worst area >  790.80\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |--- concavity error >  0.05\n",
      "|   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |--- perimeter error >  6.60\n",
      "|   |   |   |   |   |--- class: 0\n",
      "|   |   |   |--- worst radius >  17.48\n",
      "|   |   |   |   |--- class: 0\n",
      "|   |   |--- worst concave points >  0.14\n",
      "|   |   |   |--- worst texture <= 27.44\n",
      "|   |   |   |   |--- symmetry error <= 0.01\n",
      "|   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |--- symmetry error >  0.01\n",
      "|   |   |   |   |   |--- class: 1\n",
      "|   |   |   |--- worst texture >  27.44\n",
      "|   |   |   |   |--- class: 0\n",
      "|   |--- worst concave points >  0.16\n",
      "|   |   |--- worst texture <= 23.47\n",
      "|   |   |   |--- mean concave points <= 0.08\n",
      "|   |   |   |   |--- class: 1\n",
      "|   |   |   |--- mean concave points >  0.08\n",
      "|   |   |   |   |--- class: 0\n",
      "|   |   |--- worst texture >  23.47\n",
      "|   |   |   |--- class: 0\n",
      "|--- worst perimeter >  114.45\n",
      "|   |--- worst concave points <= 0.09\n",
      "|   |   |--- mean concavity <= 0.04\n",
      "|   |   |   |--- class: 0\n",
      "|   |   |--- mean concavity >  0.04\n",
      "|   |   |   |--- class: 1\n",
      "|   |--- worst concave points >  0.09\n",
      "|   |   |--- radius error <= 0.24\n",
      "|   |   |   |--- worst radius <= 18.02\n",
      "|   |   |   |   |--- class: 1\n",
      "|   |   |   |--- worst radius >  18.02\n",
      "|   |   |   |   |--- class: 0\n",
      "|   |   |--- radius error >  0.24\n",
      "|   |   |   |--- class: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, export_text\n",
    "\n",
    "# Membuat model Decision Tree\n",
    "DecisitionTreeModel = DecisionTreeClassifier(criterion=\"gini\")\n",
    "DecisitionTreeModel.fit(X_train, y_train)\n",
    "\n",
    "# Tampilkan model pohon hasil Decision Tree dengan method export_text\n",
    "text_representation = export_text(DecisitionTreeModel, feature_names= list(data.feature_names))\n",
    "print(text_representation)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Id3 Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import six\n",
    "# import sys\n",
    "# sys.modules['sklearn.externals.six'] = six\n",
    "\n",
    "# Import library ID3\n",
    "# from id3 import Id3Estimator\n",
    "\n",
    "# Membuat model ID3\n",
    "# ID3model = Id3Estimator()\n",
    "# ID3model.fit(X_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. K-Means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-647 {color: black;background-color: white;}#sk-container-id-647 pre{padding: 0;}#sk-container-id-647 div.sk-toggleable {background-color: white;}#sk-container-id-647 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-647 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-647 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-647 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-647 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-647 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-647 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-647 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-647 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-647 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-647 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-647 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-647 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-647 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-647 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-647 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-647 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-647 div.sk-item {position: relative;z-index: 1;}#sk-container-id-647 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-647 div.sk-item::before, #sk-container-id-647 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-647 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-647 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-647 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-647 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-647 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-647 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-647 div.sk-label-container {text-align: center;}#sk-container-id-647 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-647 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-647\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=50, max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-647\" type=\"checkbox\" checked><label for=\"sk-estimator-id-647\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=50, max_iter=1000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=50, max_iter=1000)"
      ]
     },
     "execution_count": 3150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "\n",
    "# Membuat model K-Means (Unsupervised Learning)\n",
    "KMeansModel = KMeans(n_clusters=2, n_init=\"auto\", init=\"k-means++\", algorithm=\"lloyd\")\n",
    "KMeansModel.fit(X_train)\n",
    "\n",
    "# Membuat model LogisticRegression untuk memberi label pada model K-Means (Supervised Learning)\n",
    "train_cluster_labels: np.ndarray[np.int32] = KMeansModel.labels_\n",
    "X_train_clustered = train_cluster_labels.reshape(-1, 1)\n",
    "\n",
    "LabeledKMeansModel = LogisticRegression(C=50, max_iter=1000)\n",
    "LabeledKMeansModel.fit(X_train_clustered, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-648 {color: black;background-color: white;}#sk-container-id-648 pre{padding: 0;}#sk-container-id-648 div.sk-toggleable {background-color: white;}#sk-container-id-648 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-648 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-648 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-648 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-648 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-648 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-648 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-648 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-648 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-648 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-648 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-648 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-648 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-648 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-648 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-648 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-648 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-648 div.sk-item {position: relative;z-index: 1;}#sk-container-id-648 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-648 div.sk-item::before, #sk-container-id-648 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-648 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-648 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-648 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-648 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-648 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-648 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-648 div.sk-label-container {text-align: center;}#sk-container-id-648 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-648 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-648\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=100, max_iter=20000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-648\" type=\"checkbox\" checked><label for=\"sk-estimator-id-648\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=100, max_iter=20000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=100, max_iter=20000)"
      ]
     },
     "execution_count": 3151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Membuat model Logistic Regression\n",
    "LogisticRegressionModel = LogisticRegression(C=100, max_iter=20000)\n",
    "LogisticRegressionModel.fit(X_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5. Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-649 {color: black;background-color: white;}#sk-container-id-649 pre{padding: 0;}#sk-container-id-649 div.sk-toggleable {background-color: white;}#sk-container-id-649 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-649 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-649 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-649 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-649 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-649 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-649 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-649 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-649 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-649 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-649 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-649 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-649 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-649 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-649 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-649 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-649 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-649 div.sk-item {position: relative;z-index: 1;}#sk-container-id-649 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-649 div.sk-item::before, #sk-container-id-649 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-649 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-649 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-649 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-649 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-649 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-649 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-649 div.sk-label-container {text-align: center;}#sk-container-id-649 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-649 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-649\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(hidden_layer_sizes=(60, 90, 30), max_iter=10000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-649\" type=\"checkbox\" checked><label for=\"sk-estimator-id-649\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(hidden_layer_sizes=(60, 90, 30), max_iter=10000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(60, 90, 30), max_iter=10000)"
      ]
     },
     "execution_count": 3152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Membuat model Neural Network\n",
    "MLPModel = MLPClassifier(hidden_layer_sizes=(60, 90, 30), max_iter=10000)\n",
    "MLPModel.fit(X_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6. Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-650 {color: black;background-color: white;}#sk-container-id-650 pre{padding: 0;}#sk-container-id-650 div.sk-toggleable {background-color: white;}#sk-container-id-650 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-650 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-650 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-650 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-650 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-650 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-650 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-650 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-650 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-650 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-650 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-650 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-650 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-650 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-650 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-650 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-650 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-650 div.sk-item {position: relative;z-index: 1;}#sk-container-id-650 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-650 div.sk-item::before, #sk-container-id-650 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-650 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-650 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-650 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-650 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-650 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-650 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-650 div.sk-label-container {text-align: center;}#sk-container-id-650 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-650 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-650\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=100, kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-650\" type=\"checkbox\" checked><label for=\"sk-estimator-id-650\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=100, kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=100, kernel='linear')"
      ]
     },
     "execution_count": 3153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Membuat model SVM\n",
    "SVCModel = SVC(C=100, kernel=\"linear\")\n",
    "SVCModel.fit(X_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Simpan model hasil pembelajaran dengan pustaka pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3154,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3155,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./bin/DecisionTreeModel.pickle\", \"wb\") as f:\n",
    "    pickle.dump(DecisitionTreeModel, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Id3 Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Save model ke dalam file"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. K-Means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3157,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./bin/KMeansModel.pickle\", \"wb\") as f:\n",
    "    pickle.dump(KMeansModel, f)\n",
    "\n",
    "with open(\"./bin/LabeledKMeansModel.pickle\", \"wb\") as f:\n",
    "    pickle.dump(LabeledKMeansModel, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3158,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./bin/LogisticRegressionModel.pickle\", \"wb\") as f:\n",
    "    pickle.dump(LogisticRegressionModel, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5. Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3159,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./bin/MLPModel.pickle\", \"wb\") as f:\n",
    "    pickle.dump(MLPModel, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6. Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3160,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./bin/SVCModel.pickle\", \"wb\") as f:\n",
    "    pickle.dump(SVCModel, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Melakukan proses prediction dengan load model dan mengevaluasi hasil prediksi dengan menggunakan metric: Accuracy, Precision, Recall, dan F1 serta menampilkan Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3161,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:   0.9122807017543859\n",
      "Precision:  0.8933333333333333\n",
      "Recall:     0.9710144927536232\n",
      "F1:         0.9305555555555556\n",
      "Confusion Matrix:\n",
      "[[37  8]\n",
      " [ 2 67]]\n"
     ]
    }
   ],
   "source": [
    "with open(\"./bin/DecisionTreeModel.pickle\", \"rb\") as f:\n",
    "    DecisitionTreeModel: DecisionTreeClassifier = pickle.load(f)\n",
    "\n",
    "    y_pred = DecisitionTreeModel.predict(X_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    conf = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    print(f\"Accuracy:   {accuracy}\")\n",
    "    print(f\"Precision:  {precision}\")\n",
    "    print(f\"Recall:     {recall}\")\n",
    "    print(f\"F1:         {f1}\")\n",
    "    print(f\"Confusion Matrix:\\n{conf}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Id3 Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Load model dari file"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. K-Means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:   0.8157894736842105\n",
      "Precision:  0.7666666666666667\n",
      "Recall:     1.0\n",
      "F1:         0.8679245283018869\n",
      "Confusion Matrix:\n",
      "[[24 21]\n",
      " [ 0 69]]\n"
     ]
    }
   ],
   "source": [
    "with open(\"./bin/KMeansModel.pickle\", \"rb\") as f:\n",
    "    KMeansModel: KMeans = pickle.load(f)\n",
    "\n",
    "    test_cluster_labels: np.ndarray[np.int32] = KMeansModel.predict(X_test)\n",
    "    X_test_clustered = test_cluster_labels.reshape(-1, 1)\n",
    "\n",
    "    with open(\"./bin/LabeledKMeansModel.pickle\", \"rb\") as f:\n",
    "        LabeledKMeansModel: LogisticRegression = pickle.load(f)\n",
    "\n",
    "        y_pred = LabeledKMeansModel.predict(X_test_clustered)\n",
    "\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        conf = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "        print(f\"Accuracy:   {accuracy}\")\n",
    "        print(f\"Precision:  {precision}\")\n",
    "        print(f\"Recall:     {recall}\")\n",
    "        print(f\"F1:         {f1}\")\n",
    "        print(f\"Confusion Matrix:\\n{conf}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:   0.9385964912280702\n",
      "Precision:  0.9428571428571428\n",
      "Recall:     0.9565217391304348\n",
      "F1:         0.9496402877697843\n",
      "Confusion Matrix:\n",
      "[[41  4]\n",
      " [ 3 66]]\n"
     ]
    }
   ],
   "source": [
    "with open(\"./bin/LogisticRegressionModel.pickle\", \"rb\") as f:\n",
    "    LogisticRegressionModel: LogisticRegression = pickle.load(f)\n",
    "\n",
    "    y_pred = LogisticRegressionModel.predict(X_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    conf = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    print(f\"Accuracy:   {accuracy}\")\n",
    "    print(f\"Precision:  {precision}\")\n",
    "    print(f\"Recall:     {recall}\")\n",
    "    print(f\"F1:         {f1}\")\n",
    "    print(f\"Confusion Matrix:\\n{conf}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5. Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:   0.9035087719298246\n",
      "Precision:  0.8717948717948718\n",
      "Recall:     0.9855072463768116\n",
      "F1:         0.9251700680272109\n",
      "Confusion Matrix:\n",
      "[[35 10]\n",
      " [ 1 68]]\n"
     ]
    }
   ],
   "source": [
    "with open(\"./bin/MLPModel.pickle\", \"rb\") as f:\n",
    "    MLPModel: MLPClassifier = pickle.load(f)\n",
    "\n",
    "    y_pred = MLPModel.predict(X_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    conf = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    print(f\"Accuracy:   {accuracy}\")\n",
    "    print(f\"Precision:  {precision}\")\n",
    "    print(f\"Recall:     {recall}\")\n",
    "    print(f\"F1:         {f1}\")\n",
    "    print(f\"Confusion Matrix:\\n{conf}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6. Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:   0.9210526315789473\n",
      "Precision:  0.9166666666666666\n",
      "Recall:     0.9565217391304348\n",
      "F1:         0.9361702127659574\n",
      "Confusion Matrix:\n",
      "[[39  6]\n",
      " [ 3 66]]\n"
     ]
    }
   ],
   "source": [
    "with open(\"./bin/SVCModel.pickle\", \"rb\") as f:\n",
    "    SVCModel: SVC = pickle.load(f)\n",
    "\n",
    "    y_pred = SVCModel.predict(X_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    conf = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    print(f\"Accuracy:   {accuracy}\")\n",
    "    print(f\"Precision:  {precision}\")\n",
    "    print(f\"Recall:     {recall}\")\n",
    "    print(f\"F1:         {f1}\")\n",
    "    print(f\"Confusion Matrix:\\n{conf}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Analisis hasil metrik evaluasi yang sudah diperoleh untuk semua algoritma pembelajaran dalam bentuk perbandingan nilai dan penjelasan singkat mengenai hasil tersebut"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setelah seluruh algoritma diaplikasikan pada setiap model pembelajaran, didapatkan bahwa rata - rata model yang dihasilkan memiliki metrik Accuracy, Precision, Recall, dan F1 Score yang cukup baik (sebagian besar melebihi 80%). Jika seluruh model pembelajaran tersebut diurutkan berdasarkan parametrik Accuracy dan F1 Score, maka model yang terbaik adalah Logistic Regression. Terdapat beberapa hal yang menyebabkan Logistic Regression cocok untuk memodel permasalahan tersebut. Model Logistic Regression umumnya digunakan untuk menangani data dengan kelas target bertipe binary (boolean). Dataset breast cancer memiliki kelas target yang bersifat binary, yaitu benign (jinak) atau malign (ganas). Selain itu, model Logistic Regression dapat bekerja dengan baik dalam menangani parameter dengan tipe data desimal (float) seperti pada permasalahan di atas.\n",
    "\n",
    "Tidak hanya model Logistic Regression, model Support Vector Machine (SVM) juga cukup akurat dalam memodelkan permasalahan breast cancer. Model SVM cocok digunakan untuk menangani berbagai permasalahan dengan jumlah parameter yang banyak (data berdimensi tinggi). Kernel SVM yang cocok digunakan untuk memodelkan permasalahan ini adalah linear kernel. Hal tersebut dikarenakan linear kernel dapat memodelkan kelas target bertipe binary secara akurat dengan mencari linear boundary (optimal hyperplane) yang memisahkan kedua kelas tersebut. Linear kernel juga cocok digunakan pada model ini dikarenakan linear kernel cenderung tidak mengalami overfitting ketika diaplikasikan pada dataset yang kecil.\n",
    "\n",
    "Model Decision Tree memiliki tingkat Accuracy dan F1 Score yang tidak jauh berbeda dengan model SVM. Hal ini dikarenakan umumnya kedua model melakukan klasifikasi berdasarkan pembuatan linear boundary yang paling optimum. Model Decision Tree bekerja dengan mencari suatu linear boundary diantara seluruh kelas dataset yang dapat memberikan maksimum Information Gain dengan perhitungan Entropy. Model Decision Tree umumnya dapat memodelkan hubungan statistik antar kelas pada dataset secara akurat. Hal tersebut dikarenakan model Decision Tree dapat juga ditranslasikan sebagai kumpulan logical rules yang dapat menggambarkan hubungan tersebut. Pada persoalan breast cancer, atribut yang terdapat di dalam tidak sepenuhnya independen antara satu sama lain, sehingga pembentukkan pohon keputusan akan memiliki simpul yang sedikit dan mudah untuk dipartisi.\n",
    "\n",
    "Setelah model Decision Tree, model yang tidak kalah akurat untuk diaplikasikan pada permasalahan breast cancer dataset adalah Multilayer Perceptron (subbagian Neural Network). Model Multilayer Perceptron dapat digunakan untuk memodelkan berbagai macam permasalahan, seperti Computer Vision, Natural Language Processing, Search Engine, dan permasalahan lainnya. Hal ini dikarenakan Multilayer Perceptron cenderung bersifat versatile dan mudah beradaptasi jika dibandingkan model pembelajaran lainnya. Namun untuk beberapa permasalahan khusus, model Multilayer Perceptron dapat diungguli oleh model pembelajaran lainnya, seperti pada permasalahan breast cancer disini. Selain itu, model Multilayer Perceptron umumnya membutuhkan perhitungan komputasi yang lebih banyak dari model pembelajaran lainnya dikarenakan adanya proses backpropagation hingga mencapai keadaan konvergen.\n",
    "\n",
    "Terakhir, model yang memiliki tingkat Accuracy dan F1 Score paling rendah adalah model K-Means Clustering yang diberi label oleh bantuan model Logistic Regression. Model K-Means Clustering merupakan algoritma unsupervised learning, sehingga model tersebut tidak dapat memberikan label akurat pada prediksi yang dilakukannya. Oleh karena itu, diperlukan model Logistic Regression yang memetakan label individu hasil perhitungan K-Means Clustering ke dalam kelas target. Perhitungan klasifikasi yang dilakukan oleh model Logistic Regression pada permasalahan ini tidak akan memiliki dampak yang signifikan terhadap perhitungan yang dilakukan oleh K-Means Clustering. Oleh karena itu, nilai Accuracy dan F1 Score yang didapatkan pada perhitungan di atas hampir seluruhnya disebabkan oleh model K-Means Clustering. K-Means Clustering umumnya digunakan untuk mencari kemiripan antara setiap instance dengan instance lainnya, lalu mengelompokkan instance tersebut ke dalam salah satu kategori. Pada umumnya, model K-Means Clustering tidak dapat memodelkan suatu dataset dengan jumlah atribut yang banyak, seperti pada persoalan breast cancer dataset di atas. Selain itu, model K-Means Clustering menanggap seluruh cluster yang terbentuk pada dataset memiliki varians yang sama (mungkin saja berbeda untuk beberapa dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a0ce89d964584776698e221a3b639718d3fe263f67ce543930e1fdcd62659475"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
